
SCRIPTDIR=$( (cd -P $(dirname $0) && pwd) )
corename=kanopy
DATADIR=${SCRIPTDIR}/data
BASEDIR=$( dirname $SCRIPTDIR )
COMMONDIR=${BASEDIR}/common


# load the shared bash functions log, vlog and Verbose
. $COMMONDIR/outputfuncs.bash 

marc4j_jar=$( find_newest_file_matching_pattern_under_directory $COMMONDIR "marc4j*.jar" )

verbose=
force=
test=
screenscrape=
index=staging:production
while getopts :vsfti: opt
 do
      case $opt in
          v) verbose=-v;;
          s) screenscrape=-s;;
          t) test=-t;;
          f) force=-f;;
          i) index=$OPTARG
      esac
done
shift $((OPTIND-1))

mkdir -p $DATADIR/records
mkdir -p $DATADIR/incoming_zip
mkdir -p $DATADIR/incoming
mkdir -p $DATADIR/processed_zip
mkdir -p $DATADIR/incoming_sorted
mkdir -p $DATADIR/processed
mkdir -p $DATADIR/updates_incoming
mkdir -p $DATADIR/screenshots
#if [[ ! -d $COMMONDIR/node_modules ]] ; then
#    Echo "Node modules not installed in common directory.  Exiting"
#    exit 1
#fi

#if [[ ! -d $SCRIPTDIR/node_modules || ! -L $SCRIPTDIR/node_modules ]] ; then  
#   ln -s $COMMONDIR/node_modules $SCRIPTDIR/node_modules
#fi

#if [[ ! -f $COMMONDIR/package-lock.json ]] ; then
#    Echo "package-lock.json not installed in common directory.  Exiting"
#    exit 1
#fi

diff --normal $SCRIPTDIR/cores_to_process $SCRIPTDIR/cores_to_process 2> /dev/null > /dev/null
if [[ $? != 0 ]] ; then
Verbose "Running Busybox, diff is different"
diff_flag=
else
Verbose "Not running Busybox, all is well"
diff_flag=-u
fi

if [[ "$screenscrape" == "-s" ]] ; then
    Verbose "Calling script to download latest records from Website"
    $SCRIPTDIR/getkanopyrecordsviapuppeteer $verbose $force
    if [[ "$?" != "0" ]]; then
        Echo "Script to fetch records returned error, exiting"
        exit 1
    fi
else
    Verbose "Skipping script to download latest records from website"
fi 

BUCKET="s3://virgo4-ingest-raw-upload-production/kanopy"
KEY=`aws s3 ls $BUCKET --recursive 2> /dev/null | sort | tail -n 1 | sed -e 's#.*kanopy/##' `

if [[ "$KEY" != "" ]] ; then
    Verbose "Downloading latest file from AWS bucket $BUCKET"
    aws s3 cp "$BUCKET/" $DATADIR/incoming_zip/ --recursive --exclude "*" --include "$KEY" 2> /dev/null
    Verbose "Checking whether it has been processed already"
    alreadydone=0
    for file in `find $DATADIR/processed_zip -name "*.zip"` 
    do 
        cmp -s "$file" "$DATADIR/incoming_zip/$KEY"
        return=$?
        if [[ $return == "0" ]] ; then  
            alreadydone=1
        fi
    done
    if [[ "$alreadydone" == "1" ]] ; then 
        Verbose "Downloaded file already processed"
        rm "$DATADIR/incoming_zip/$KEY"
        exit 0
    else 
        Verbose "Downloaded file needs to be processed"
    fi
fi

Verbose "unpack downloaded zip file"
latest_zip_file=$( find_newest_file_matching_pattern_under_directory $DATADIR/incoming_zip "Kanopy_MARC*.zip" )
Verbose "latest file is $latest_zip_file"

if [[ "$latest_zip_file" != "" ]]; then
    froot=`basename "$latest_zip_file"`
    format=`file -b "$latest_zip_file"  | cut -d' ' -f1-3 `
    if [[ "$format" == "Zip archive data," ]] ; then
        Verbose "    Unpacking zipfile $froot"
        unzip -o -q "$DATADIR/incoming_zip/$froot" -d $DATADIR/incoming
    else
        Echo "Error:  downloaded file not in .zip format -- it is: $(file -b $file)"
    fi
    mv  "$DATADIR/incoming_zip/$froot" $DATADIR/processed_zip
else
    Echo "No new zip file downloaded, nothing to do.  Exiting"
    exit 0
fi

DATE=`date +%Y%m%d%H%M`
YEAR=`date +%Y`

touch $DATADIR/records/all_kanopy_records.mrc
touch $DATADIR/records/all_kanopy_records_edited.mrc

#Handle preparing these record for Virgo 4 and uploading them to Amazon S3 bucket
cat $SCRIPTDIR/kanopy_shadowed_map.properties | egrep -v "^#" | egrep -v "DEFAULT" | tr "=" "|" > $DATADIR/kanopy_shadowed_map.map

if [[ ! -s $DATADIR/records/all_kanopy_records_edited_bak.mrc ]] ; then
    force=-f
fi

cp $DATADIR/records/all_kanopy_records.mrc $DATADIR/records/all_kanopy_records_bak.mrc
cp $DATADIR/records/all_kanopy_records_edited.mrc $DATADIR/records/all_kanopy_records_edited_bak.mrc

for file in `find $DATADIR/incoming -type f -name "*.mrc"`
do
    froot=`basename $file`
    $COMMONDIR/marcsort -q $file > $DATADIR/incoming_sorted/$froot
    rm $file
    Verbose "    counting records in full dump and in update"
    Verbose "    Replacing full record dump with contents of $froot"
    cp $DATADIR/incoming_sorted/$froot $DATADIR/records/all_kanopy_records.mrc
    mv $DATADIR/incoming_sorted/$froot $DATADIR/processed
done 

java -cp "$marc4j_jar:$COMMONDIR/fix_boundwith.jar" AddFieldToRecord -c utf8 -f 988 -s a  $DATADIR/records/all_kanopy_records.mrc $DATADIR/kanopy_shadowed_map.map | $COMMONDIR/to_xml -edit $SCRIPTDIR/video_recs_map.properties | sed -e 's/^\([ ]*<marc:leader>.....\)...\(.*\)/\1ngm\2/' | $COMMONDIR/to_utf8 > $DATADIR/records/all_kanopy_records_edited.mrc

if [[ "$force" != "-f" ]] ; then
    # Handle incremental updates.
    Verbose "    Extracting changed records" 
    $COMMONDIR/marcdiff -mrc2 $DATADIR/records/all_kanopy_records_edited_bak.mrc $DATADIR/records/all_kanopy_records_edited.mrc > $DATADIR/updates_incoming/new_$DATE.mrc

    Verbose "    Checking for deleted records"
    cat $DATADIR/records/all_kanopy_records_edited.mrc  | $COMMONDIR/getrecord -id > $DATADIR/records/all_kanopy_records.ids
    cat $DATADIR/records/all_kanopy_records_edited_bak.mrc  | $COMMONDIR/getrecord -id > $DATADIR/records/all_kanopy_records_bak.ids

    num_current=`cat $DATADIR/records/all_kanopy_records.ids | wc -l`
    num_previous=`cat $DATADIR/records/all_kanopy_records_bak.ids | wc -l`
    Verbose "Newly transformed file contains $num_current records for $corename"
    Verbose "Previous file contains $num_previous records for $corename"

    diff $diff_flag $DATADIR/records/all_kanopy_records_bak.ids $DATADIR/records/all_kanopy_records.ids | egrep '^-' | egrep -v "^---" | cut -c 2- > $DATADIR/updates_incoming/deletes_$DATE.del

    num_to_delete=`cat $DATADIR/updates_incoming/deletes_$DATE.del | wc -l`
    Verbose "Diff output contains $num_to_delete records for $corename"
    if [[ "$num_current" != "$num_prevous" && "$num_to_delete" == "0" ]] ; then
        diff $diff_flag $DATADIR/records/all_kanopy_records_bak.ids $DATADIR/records/all_kanopy_records.ids | vlog
    fi

    for line in `cat $SCRIPTDIR/cores_to_process`
        do
        solrname=`echo $line| cut -d '|' -f1`
        mkdir -p $DATADIR/updates_${solrname}
    
        if [[ -s $DATADIR/updates_incoming/new_$DATE.mrc ]] ; then
            cp $DATADIR/updates_incoming/new_$DATE.mrc $DATADIR/updates_${solrname}
        fi
        if [[ -s $DATADIR/updates_incoming/deletes_$DATE.del ]] ; then
            cp $DATADIR/updates_incoming/deletes_$DATE.del $DATADIR/updates_${solrname}/deletes_$DATE.ids
        fi
    done

    rm  $DATADIR/updates_incoming/new_$DATE.mrc
    rm  $DATADIR/updates_incoming/deletes_$DATE.del
fi

for line in `cat $SCRIPTDIR/cores_to_process`
do
    solrname=`echo $line| cut -d '|' -f1`
    update_bucket=`echo $line| cut -d '|' -f2 | sed -e "s/YEAR/$YEAR/"`
    delete_bucket=`echo $line| cut -d '|' -f3 | sed -e "s/YEAR/$YEAR/"`
    solrurl=`echo $line| cut -d '|' -f4`

    if [[ "$index" =~ $solrname ]]; then
        if [[ "$force" != "-f" ]] ; then
            Verbose "    Checking whether any records need reindexing for index $solrname"
            for update in `find $DATADIR/updates_$solrname -name "*.mrc" | sort`
            do  
                upname=`basename $update`
                if [[ -s $update ]] ; then
                    if [[ "$test" != "-t" ]] ; then
                        aws s3 cp $update ${update_bucket}/$upname 2>/dev/null | vlog "      "
                        rm $update
                    else 
                        Verbose "would upload $update to $solrname bucket"
                    fi
                fi
            done
            for update in `find $DATADIR/updates_$solrname -name "*.ids" | sort`
            do  
                upname=`basename $update`
                if [[ -s $update ]] ; then
                    if [[ "$test" != "-t" ]] ; then
                        aws s3 cp $update ${delete_bucket}/$upname 2>/dev/null | vlog "      "
                        rm $update
                    else 
                        Verbose "would upload $update to $solrname delete bucket"
                    fi
                fi
            done
        else
            Verbose "Due to -f flag, Reindexing all records"
            Verbose "First figure out if any records need to be deleted"
            cat $DATADIR/records/all_kanopy_records_edited.mrc  | $COMMONDIR/getrecord -id | sort > $DATADIR/records/all_kanopy_records.ids
            curl -s "$solrurl/select?fl=id&q=data_source_f%3A${corename}&rows=10000" | egrep '"id":' | sed -e 's/.*":"//' -e 's/".*$//' | sort  > $DATADIR/cur_ids_in_solr.ids
            diff ${diff_flag} $DATADIR/cur_ids_in_solr.ids $DATADIR/records/all_kanopy_records.ids | egrep '^-' | egrep -v "^---" | cut -c 2- > $DATADIR/records_to_delete_${corename}_${solrname}.ids

            if [ -s $DATADIR/records_to_delete_${corename}_${solrname}.ids ] ; then
                Verbose "Some records in virgo solr that are not in the new dump of all records"
                if [ "$test" != "-t" ]; then
                    aws s3 cp $DATADIR/records_to_delete_${corename}_${solrname}.ids ${delete_bucket}/records_to_delete_${corename}_${solrname}.ids 2>/dev/null | vlog "      "
                else
                    Echo "would upload $DATADIR/records_to_delete_${corename}_${solrname}.ids to ${delete_bucket}"
                fi
            else
               Verbose "    No records need to be deleted"
            fi

            if [ "$test" != "-t" ]; then
                aws s3 cp $DATADIR/records/all_kanopy_records_edited.mrc ${update_bucket}/all_kanopy_records_edited.mrc 2>/dev/null | vlog "      "
            else 
                Echo "would upload $DATADIR/records/all_kanopy_records_edited.mrc to $update_bucket"
            fi
        fi
    fi
done

Verbose "    Done updating core $corename"

