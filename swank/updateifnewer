#!/bin/bash

SCRIPTDIR=$( (cd -P $(dirname $0) && pwd) )
corename=swank
DATADIR=${SCRIPTDIR}/data
BASEDIR=$( dirname $SCRIPTDIR )
COMMONDIR=${BASEDIR}/common

# load the shared bash functions log, vlog and Verbose
. $COMMONDIR/outputfuncs.bash 

marc4j_jar=$( find_newest_file_matching_pattern_under_directory $COMMONDIR "marc4j*.jar" )

DROPBOX_DIR=/lib_content30/Metadata_dropbox/swank/

verbose=
force=
test=
index=staging:production
while getopts :vfti: opt
 do
      case $opt in
          v) verbose=-v;;
          t) test=-t;;
          f) force=-f;;
          i) index=$OPTARG
      esac
done
shift $((OPTIND-1))

DATE=`date +%Y%m%d`
YEAR=`date +%Y`

#$SCRIPTDIR/getswankrecordsviacasperjs $verbose $force
swank_currentdir=$DATADIR/swank/unzip
swank_prevdir=$DATADIR/swank/prev_unzip
latest_file=$DATADIR/swank/digital_campus-content_export.zip
#dropbox_file=$DROPBOX_DIR/digital_campus-content_export.zip
dropbox_file=$( find_newest_file_matching_pattern_under_directory $DROPBOX_DIR "*.zip" )
mkdir -p $swank_currentdir
mkdir -p $swank_prevdir

if [[ ! -s "$latest_file" ]] ; then
    touch -d "A year ago" "$latest_file"
fi

if [[ "$force" == "-f" ]] ; then
    Verbose "Forcing a rebuild of all records" 
    touch -d "A year ago" "$latest_file"
fi

if [[ "$dropbox_file" != "" && -s "$dropbox_file" && "$dropbox_file" -nt "$latest_file" ]] ; then
    Verbose "New file found in dropbox: $dropbox_file"
    Verbose "backing up most recent files"
    #rm $swank_prevdir/*
    mv -f $swank_currentdir/* $swank_prevdir 2> /dev/null
    Verbose "unzipping and renaming latest files"
    unzip $dropbox_file  -d $swank_currentdir
    chmod 644 $swank_currentdir/*

    EXPORT_DATE=`ls $swank_currentdir/marc_record_export[-_][0-9]*.mrc | tail -1 | sed -e 's/.*marc_record_export[-_]//' -e 's/.mrc//'`
    mv $swank_currentdir/digcampus_export.csv $swank_currentdir/digcampus_export_${EXPORT_DATE}.csv
    mv $swank_currentdir/marc_record_export-${EXPORT_DATE}.mrc  $swank_currentdir/marc_record_export_${EXPORT_DATE}.mrc 

    Verbose "making .TSV file from .CSV file"
    # process the downloaded csv file to create a tab separated file to use in shadowing records for which the license has expired
    egrep -v '^Title'  $swank_currentdir/digcampus_export_${EXPORT_DATE}.csv | cut -d ',' -f 5 | sed -e 's#.*/en/##' -e 's/small.jpg.*//' -e 's/[-_][0-9]*//' > $swank_currentdir/swank_ids_${EXPORT_DATE}.txt
    egrep -v '^Title' $swank_currentdir/digcampus_export_${EXPORT_DATE}.csv  | cut -d ',' -f 1,7 | tr ',' '\t' | paste $swank_currentdir/swank_ids_${EXPORT_DATE}.txt - > $swank_currentdir/swank_${EXPORT_DATE}.tsv

    # link the generic files to the more recent one
    ln -sf $swank_currentdir/marc_record_export_${EXPORT_DATE}.mrc $DATADIR/swank/swank_casper.mrc
    ln -sf $swank_currentdir/swank_${EXPORT_DATE}.tsv $DATADIR/swank/swank_casper.tsv
    
    # process the tab separated file and the set of marc records to create a set of records that contains the license expiration date 
    # for use in Virgo 4 
    cat $swank_currentdir/swank_${EXPORT_DATE}.tsv | cut -f 1,3 | tr '/' '\t' | awk '{printf "%s|%4d%02d%02d\n", $1, $4, $2, $3 }' > $swank_currentdir/swank_casper_${EXPORT_DATE}.date
    java -cp "$marc4j_jar:$COMMONDIR/fix_boundwith.jar" AddFieldToRecord -c utf8 -f 988 -s a  $swank_currentdir/marc_record_export_${EXPORT_DATE}.mrc $swank_currentdir/swank_casper_${EXPORT_DATE}.date > $swank_currentdir/marc_record_export_edited_${EXPORT_DATE}.mrc


    for line in `cat $SCRIPTDIR/cores_to_process`
    do
        solrname=`echo $line| cut -d '|' -f1`
        update_bucket=`echo $line| cut -d '|' -f2 | sed -e "s/YEAR/$YEAR/"`
        delete_bucket=`echo $line| cut -d '|' -f3 | sed -e "s/YEAR/$YEAR/"`
        solrurl=`echo $line| cut -d '|' -f4`

        if [[ "$index" =~ $solrname ]]; then
            Verbose "Checking for records to delete from Solr"
            cat $swank_currentdir/marc_record_export_edited_${EXPORT_DATE}.mrc| 
                $COMMONDIR/getrecord -id | sort -n |  sed -e 's/^/swank_/' > $swank_currentdir/swank_ids_in_dump.ids

            curl -s "${solrurl}/select?fl=id&q=data_source_f:swank&defType=lucene&rows=1000" | 
                egrep '"id":' | sed -e 's/.*:"//' -e 's/".*$//' | sort -n > $swank_currentdir/swank_ids_in_${solrname}_solr.ids

            diff $swank_currentdir/swank_ids_in_dump.ids $swank_currentdir/swank_ids_in_${solrname}_solr.ids | 
                egrep '>' | sed -e 's/> //' > $swank_currentdir/swank_ids_to_delete_from_${solrname}_solr.ids

            if [[ "$test" != "-t" ]] ; then 
                if [[ -s $swank_currentdir/swank_ids_to_delete_from_${solrname}_solr.ids ]] ; then
                    Verbose "Delete older records from Solr"
                    $AWS s3 cp  $swank_currentdir/swank_ids_to_delete_from_${solrname}_solr.ids  ${delete_bucket}/swank_ids_to_delete_from_${solrname}_solr.ids  2>&1 | vlog "      "
                fi

                Verbose "Uploading to S3 bucket for Virgo4"
                $AWS s3 cp  $swank_currentdir/marc_record_export_edited_${EXPORT_DATE}.mrc  ${update_bucket}/marc_record_export_edited_${EXPORT_DATE}.mrc 2>&1 | vlog "      "
            else 
                if [[ -s $swank_currentdir/swank_ids_to_delete_from_${solrname}_solr.ids ]] ; then
                    Echo "would upload $swank_currentdir/swank_ids_to_delete_from_${solrname}_solr.ids to ${delete_bucket}"
                fi
                Echo "would upload $swank_currentdir/marc_record_export_edited_${EXPORT_DATE}.mrc to ${update_bucket}"
            fi
        fi


        if [[ "$test" != "-t" ]] ; then 
            Verbose "Copying Dropbox file to \"Latest\" file"
            cp $dropbox_file $latest_file 
        fi
    done
else
    Verbose "No new file in dropbox, so nothing to do."
fi
